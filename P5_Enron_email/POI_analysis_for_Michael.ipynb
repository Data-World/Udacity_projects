{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "                                                \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn import cross_validation\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from tester import test_classifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import scipy.stats as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = \"final_project_dataset.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Data load functions\n",
    "\n",
    "def import_data(data):\n",
    "    '''This are the things I will do to import the data everytime, \n",
    "    regardless of what variables I make.'''\n",
    "    with open(data, \"r\") as data_file:\n",
    "        data_dict = pickle.load(data_file)\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    df = df.transpose()\n",
    "    df = df.drop('email_address', axis=1)\n",
    "    df = df.astype(float)\n",
    "    df = df.drop('TOTAL')\n",
    "    df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "    df = df.drop(\"loan_advances\", axis=1)\n",
    "    return df\n",
    "def import_data1(data):\n",
    "    '''This are the things I will do to import the data everytime, \n",
    "    regardless of what variables I make.'''\n",
    "    with open(data, \"r\") as data_file:\n",
    "        data_dict1 = pickle.load(data_file)\n",
    "    return data_dict1\n",
    "\n",
    "def get_df_features_labels_features_list(df):\n",
    "    '''This is where the features and labels are extracted to use as arguments\n",
    "    for sklearn\\'s StratifiedShuffleSplit function AND for the model that I submit\n",
    "    to the grader. That is why it returns four things. It is also where I add some \n",
    "    new variables.'''\n",
    "    \n",
    "    #df = df.drop('email_address', axis=1)\n",
    "    \n",
    "    df = df.astype(float)\n",
    "    \n",
    "    #add columns\n",
    "    df['pct_from_poi'] = df['from_poi_to_this_person']/(df['from_messages'] + 1)\n",
    "    df['pct_to_poi'] = df['from_this_person_to_poi']/(df['from_messages'] + 1)\n",
    "    df['to_from'] = df['pct_from_poi']*df['pct_from_poi']\n",
    "    \n",
    "    #drop columns\n",
    "    #df = df.drop(\"loan_advances\", axis=1)\n",
    "    #df = df.drop('restricted_stock_deferred', axis=1)\n",
    "    #df = df.drop('director_fees', axis=1)\n",
    "    #df = df.drop('restricted_stock', axis=1)\n",
    "    #df = df.drop('deferral_payments', axis=1)\n",
    "    #df = df.drop('deferred_income', axis=1)\n",
    "   \n",
    "    # drop rows based on meaning\n",
    "\n",
    "    #df = df.drop('TOTAL')\n",
    "    #df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "    #df = df.drop(\"LOCKHART EUGENE E\")\n",
    "\n",
    "\n",
    "\n",
    "    #drop rows\n",
    "    for i in df.index:\n",
    "        if df.ix[i].count() < 3:\n",
    "            df = df.drop(i, axis=0)\n",
    "    \n",
    "    features_list = list(df.columns)\n",
    "    features_list.remove('poi')\n",
    "    # get features of udacity_grader\n",
    "    features = df[features_list]\n",
    "    labels = df['poi']\n",
    "    # put poi back in for udacity grader\n",
    "    features_list.insert(0,'poi')\n",
    "\n",
    "    \n",
    "    return df, features, labels, features_list\n",
    "\n",
    "## precision recall functiom \n",
    "def precision_recall(labels,predictions):\n",
    "    ind_true_pos = [i for i in range(0,len(labels)) if (predictions[i]==1) & (labels[i]==1)]\n",
    "    ind_false_pos = [i for i in range(0,len(labels)) if ((predictions[i]==1) & (labels[i]==0))]\n",
    "    ind_false_neg = [i for i in range(0,len(labels)) if ((predictions[i]==0) & (labels[i]==1))]\n",
    "    ind_true_neg = [i for i in range(0,len(labels)) if ((predictions[i]==0) & (labels[i]==0))]\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    true_pos = len(ind_true_pos)\n",
    "    false_pos = len(ind_false_pos)\n",
    "    true_neg = len(ind_true_neg)\n",
    "    false_neg = len(ind_false_neg)\n",
    "    \n",
    "    ind_labels = [i for i in range(0,len(labels)) if labels[i]==1]\n",
    "    \n",
    "    if len(ind_labels) !=0:\n",
    "        if float( len(ind_true_pos) + len(ind_false_pos))!=0:\n",
    "            precision = float(len(ind_true_pos))/float( len(ind_true_pos) + len(ind_false_pos))\n",
    "        if float( len(ind_true_pos) + len(ind_false_neg))!=0:\n",
    "            recall = float(len(ind_true_pos))/float( len(ind_true_pos) + len(ind_false_neg))\n",
    "        \n",
    "        \n",
    "        return precision, recall,true_pos,true_neg,false_pos,false_neg\n",
    "    else:\n",
    "        return -1,-1,0,0,0,0\n",
    "\n",
    "def custom_scorer(labels, predictions):\n",
    "    precision,recall = precision_recall(labels,predictions)\n",
    "    min_score = min(precision, recall)\n",
    "    return min_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__n_estimators': 100, 'imp__strategy': 'median', 'pca__n_components': 3, 'clf__max_depth': 6, 'clf__learning_rate': 0.1, 'clf__loss': 'exponential', 'selection__k': 16}\n",
      "make_scorer(custom_scorer)\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Get custom scorer\n",
    "score = make_scorer(custom_scorer, greater_is_better=True)\n",
    "\n",
    "# get the df\n",
    "df = import_data(data)\n",
    "\n",
    "#df.fillna(inplace=True, value=0)\n",
    "\n",
    "# Get data, here with the features unrealated to poi dropped AND Tanya's features added.\n",
    "df, features, labels, features_list = get_df_features_labels_features_list(df)\n",
    "df1 = df.transpose()\n",
    "df1 = df1.to_dict()\n",
    "# Get the test-train split\n",
    "# features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels)\n",
    "\n",
    "# Build pipeline\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN')),\n",
    "        ('std', MinMaxScaler()),\n",
    "        ('selection', SelectKBest()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', GradientBoostingClassifier(random_state=0))\n",
    "    ])\n",
    "\n",
    "# Build Grid\n",
    "# pre-processing\n",
    "k = [k for k in range(16,17)]\n",
    "c = [x for x in range(3,4)]\n",
    "\n",
    "# estimator parameters\n",
    "e = [100]\n",
    "r = [0.1]\n",
    "d = [d for d in range(6, 7)]\n",
    "l = [\"exponential\"]\n",
    "\n",
    "param_grid = {'selection__k': k,\n",
    "              'pca__n_components': c,\n",
    "              'imp__strategy': ['median'],\n",
    "              'clf__n_estimators': e,\n",
    "              'clf__learning_rate': r,\n",
    "              'clf__max_depth': d,\n",
    "              'clf__loss': l\n",
    "             }\n",
    "\n",
    "# set model parameters to grid search object\n",
    "gridCV_object = GridSearchCV(estimator = Pipeline, \n",
    "                             param_grid = param_grid,\n",
    "                             scoring = score,\n",
    "                             cv = StratifiedShuffleSplit(labels, test_size=0.1,  n_iter=1000, random_state = 42))\n",
    "\n",
    "# train the model\n",
    "gridCV_object.fit(features, labels)\n",
    "\n",
    "print gridCV_object.best_params_\n",
    "print gridCV_object.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## making classifier\n",
    "\n",
    "from tester import test_classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "\n",
    "clf = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN')),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('selection', SelectKBest(k=16)),\n",
    "        ('pca', PCA(n_components=3)),\n",
    "        ('clf', GradientBoostingClassifier(n_estimators=100,loss=\"exponential\", max_depth=6, learning_rate=0.1))\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision: 0.2215 , Mean Recall: 0.2\n",
      "STD Precision: 0.3498 , STD Recall: 0.2828\n",
      "CI Precision: (0.15174165433084907, 0.29125834566915088)\n",
      "CI_recall: (0.14359513660445378, 0.25640486339554625)\n",
      "Overall calculation.\n",
      "\n",
      "Total predictions 1500\n",
      "True-positive:  40\n",
      "False-positive:  116\n",
      "True-negative:  1184\n",
      "False-negative:  160\n",
      "\n",
      "Accuracy:  0.816\n",
      "Precision:  0.25641025641\n",
      "Recall:  0.2\n",
      "\n",
      "\n",
      "And these are the results going through the test classifier:\n",
      "\n",
      "precision,recall =  0.276315789474 0.21\n",
      "\tAccuracy: 0.82133\tPrecision: 0.27632\tRecall: 0.21000\tF1: 0.23864\tF2: 0.22059\n",
      "\tTotal predictions: 1500\tTrue positives:   42\tFalse positives:  110\tFalse negatives:  158\tTrue negatives: 1190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## below is code to check precision and recall. This part is similar to what the grader uses.\n",
    "\n",
    "features_array = np.array(features)\n",
    "labels_array = np.array(labels)\n",
    "i_count = 0\n",
    "precision_all = []\n",
    "recall_all = []\n",
    "true_pos_all = 0\n",
    "true_neg_all = 0\n",
    "false_pos_all = 0\n",
    "false_neg_all = 0\n",
    "    \n",
    "cv = StratifiedShuffleSplit(labels, test_size=0.1,  n_iter=100, random_state = 42)\n",
    "# get_CI_mean_PrecisionRecall(features_array, labels,gridCV_object,cv)\n",
    "for train_index, test_index in cv:\n",
    "        X_train, X_test = features_array[train_index], features_array[test_index]\n",
    "        y_train, y_test = labels_array[train_index], labels_array[test_index]\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        precision,recall,true_pos,true_neg,false_pos,false_neg = precision_recall(y_test,predictions)\n",
    "    \n",
    "        if precision!=-1:\n",
    "            i_count +=1\n",
    "            #print i_count, \"Precision:\", round(precision, 4), \" , Recall:\", round(recall, 4)\n",
    "            precision_all.append(precision)\n",
    "            recall_all.append(recall)\n",
    "            true_pos_all = true_pos_all+true_pos\n",
    "            true_neg_all = true_neg_all+true_neg\n",
    "            false_pos_all = false_pos_all+false_pos\n",
    "            false_neg_all = false_neg_all+false_neg\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "precision_all = np.array(precision_all)\n",
    "recall_all = np.array(recall_all)\n",
    "mean_precision = round(np.mean(precision_all), 4)\n",
    "mean_recall = round(np.mean(recall_all), 4)\n",
    "std_precision = round(np.std(precision_all), 4)\n",
    "std_recall = round(np.std(recall_all), 4)\n",
    "                           \n",
    "print \"Mean Precision:\", mean_precision, \", Mean Recall:\", mean_recall\n",
    "print \"STD Precision:\", round(np.std(precision_all), 4), \", STD Recall:\", round(np.std(recall_all), 4)\n",
    "CI_recall = st.t.interval(0.95, len(recall_all)-1, loc=np.mean(recall_all), scale=st.sem(recall_all))\n",
    "CI_precision= st.t.interval(0.95, len(precision_all)-1, loc=np.mean(precision_all), scale=st.sem(precision_all))\n",
    "print \"CI Precision:\", CI_precision\n",
    "print \"CI_recall:\", CI_recall\n",
    "\n",
    "print \"Overall calculation.\"\n",
    "print \"\"\n",
    "print \"Total predictions\",true_pos_all+false_pos_all+true_neg_all+false_neg_all\n",
    "print \"True-positive: \",true_pos_all\n",
    "print \"False-positive: \",false_pos_all\n",
    "print \"True-negative: \",true_neg_all\n",
    "print \"False-negative: \",false_neg_all\n",
    "\n",
    "print \"\"\n",
    "print \"Accuracy: \",float(true_pos_all+true_neg_all)/float(true_pos_all+false_pos_all+true_neg_all+false_neg_all)\n",
    "print \"Precision: \",float(true_pos_all)/float(true_pos_all+false_pos_all)\n",
    "print \"Recall: \", float(true_pos_all)/float(true_pos_all+false_neg_all)\n",
    "\n",
    "\n",
    "print \"\\n\\nAnd these are the results going through the test classifier:\\n\"\n",
    "test_classifier(clf, df1, features_list,folds = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
